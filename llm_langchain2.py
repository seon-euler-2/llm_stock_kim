import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from graph_chart import draw_backtest_chart
from langchain_core.tools import tool
from datetime import datetime
import pytz
import yfinance as yf
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import streamlit.components.v1 as components
from dotenv import load_dotenv
load_dotenv()


llm = ChatOpenAI(model = 'gpt-4o')

# ë„êµ¬ í•¨ìˆ˜ ì •ì˜
@tool
def get_current_time(timezone: str, location: str) -> str:
    """í˜„ì¬ ì‹œê°ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜."""
    try:
        tz = pytz.timezone(timezone)
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        result = f'{timezone} ({location}) í˜„ì¬ì‹œê° {now}'
        print(result)
        return result
    except pytz.UnknownTimeZoneError:
        return f"ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì„ì¡´: {timezone}"

@tool
def get_yf_stock_history(ticker: str, period: str) -> str:
    """
    ì¢…ëª©ì˜ ì£¼ê°€ ì´ë ¥ì„ ì¡°íšŒí•´ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì‹œê°í™”ëŠ” ë³„ë„ ë„êµ¬ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    stock = yf.Ticker(ticker)
    df = stock.history(period=period)

    if df.empty:
        return f"{ticker}ì˜ {period} ê¸°ê°„ ì£¼ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # âœ… ì‹œê°í™”ë¥¼ ìœ„í•´ ë°ì´í„° ì €ì¥
    st.session_state["latest_history_chart"] = df[["Close"]].copy()
    st.session_state["latest_history_chart"].index = st.session_state["latest_history_chart"].index.strftime("%Y-%m-%d")

    return df.tail().to_markdown()

@tool
def get_yf_stock_info(ticker: str) -> str:
    """í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    stock = yf.Ticker(ticker)
    info = stock.info
    return str(info)

@tool
def get_yf_stock_recommendations(ticker: str) -> str:
    """í•´ë‹¹ ì¢…ëª©ì˜ ë¦¬ì„œì¹˜ ì¶”ì²œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    stock = yf.Ticker(ticker)
    recommendations = stock.recommendations
    if recommendations is None or recommendations.empty:
        return f"{ticker}ì— ëŒ€í•œ ì¶”ì²œ ë¦¬ì„œì¹˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    return recommendations.to_markdown()

@tool
def plot_history_chart() -> str:
    """
    ê°€ì¥ ìµœê·¼ì— ì¡°íšŒí•œ ì£¼ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
    (get_yf_stock_history ì´í›„ì— í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤)
    """
    df = st.session_state.get("latest_history_chart")

    if df is None or df.empty:
        return "â— ì‹œê°í™”í•  ì£¼ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € get_yf_stock_historyë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”."

    st.subheader("ğŸ“ˆ ì£¼ê°€ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸")
    st.line_chart(df, use_container_width=True)
    return "âœ… ì£¼ê°€ íˆìŠ¤í† ë¦¬ ì°¨íŠ¸ ì‹œê°í™” ì™„ë£Œ"


# ë„êµ¬ ë°”ì¸ë”©
# ----- ë„êµ¬ ë°”ì¸ë”© -----
tools = [
    get_current_time,
    get_yf_stock_info,
    get_yf_stock_history,
    get_yf_stock_recommendations,
    plot_history_chart,  # âœ… ì¶”ê°€
]
# nameì„ í‚¤ë¡œ í•˜ëŠ” dict ìƒì„±
tool_dict = {tool.name: tool for tool in tools}

llm_with_tools = llm.bind_tools(tools)


# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages):
    response = llm_with_tools.stream(messages) # â‘  llm.stream()ì„ llm_with_tools.stream()ë¡œ ë³€ê²½
    
    gathered = None # â‘¡
    for chunk in response:
        yield chunk
        
        if gathered is None: #  â‘¢
            gathered = chunk
        else:
            gathered += chunk
 
    if gathered.tool_calls:
        st.session_state.messages.append(gathered)
        
        for tool_call in gathered.tool_calls:
            selected_tool = tool_dict[tool_call['name']]
            tool_msg = selected_tool.invoke(tool_call) 
            print(tool_msg, type(tool_msg))
            st.session_state.messages.append(tool_msg)
           
        for chunk in get_ai_response(st.session_state.messages):
            yield chunk


# Streamlit ì•±
st.title("ğŸ’¬ GPT-4o Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë•ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë´‡ì´ë‹¤. "),  
        AIMessage("How can I help you?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, ToolMessage):
            st.chat_message("tool").write(msg.content)


# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    response = get_ai_response(st.session_state["messages"])
    
    result = st.chat_message("assistant").write_stream(response) # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(result)) # AI ë©”ì‹œì§€ ì €ì¥    